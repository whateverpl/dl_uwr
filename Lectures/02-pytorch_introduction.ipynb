{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/janchorowski/nn_assignments/blob/nn18/lectures/14_aevb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "torch.Size([5, 4])\n",
      "\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# Similar to numpy\n",
    "x_torch = torch.ones(5, 4)\n",
    "print(x_torch)\n",
    "print(x_torch.shape) #alias for x.size()\n",
    "print()\n",
    "y_np = np.ones((5,4))\n",
    "print(y_np)\n",
    "print(y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand: tensor([[0.7769, 0.3073],\n",
      "        [0.9303, 0.0223]])\n",
      "from_list: tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "element wise: tensor([[0.7769, 0.6147],\n",
      "        [3.7210, 0.1114]])\n",
      "matrix multiplication:  tensor([[2.0062, 3.0904],\n",
      "        [1.0193, 1.9719]])\n"
     ]
    }
   ],
   "source": [
    "# Rand\n",
    "rand = torch.rand(2,2)\n",
    "print('rand:', rand)\n",
    "# From List\n",
    "from_list = torch.tensor([[1.,2.], [4., 5.]])\n",
    "print('from_list:', from_list)\n",
    "x = rand * from_list\n",
    "print('element wise:', x)\n",
    "y = rand @ from_list\n",
    "print('matrix multiplication: ', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arange: tensor([[0],\n",
      "        [1]])\n",
      "res: tensor([[1., 2.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "#  broadcasting also works as expected\n",
    "arange = torch.arange(2)[:, None]\n",
    "print('arange:', arange)\n",
    "res = from_list + arange\n",
    "print('res:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in place\n",
    "res.add_(2)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n",
    "    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n",
      "[[[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "#But some functionalities are diffrent\n",
    "#You have been warned\n",
    "x_torch = x_torch.view(2, 2, -1)\n",
    "print(x_torch)\n",
    "\n",
    "y_np = y_np.reshape(2, 2, -1)\n",
    "print(y_np)\n",
    "\n",
    "# In torch there is also `reshape` function. But it beahves difrentlly.\n",
    "# It sometimes can make a copy of an array instead of a reference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you have a one element tensor, use ``.item()`` to get the value as a\n",
    "Python number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5099])\n",
      "0.5099312663078308 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item(), type(x.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Numpy bridge\n",
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "Transformation do not need copying underlying C array. Only `python` properties of the object has to be changed\n",
    "\n",
    "### Conclussion: It is fast\n",
    "Sometimes it is easier to transofrm data in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "See how the numpy array changed in value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Converting NumPy Array to Torch Tensor\n",
    "\n",
    "See how changing the np array changed the Torch Tensor automatically\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to\n",
    "NumPy and back.\n",
    "\n",
    "# CUDA Tensors\n",
    "\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method. To interact with each other both tensors have to be on the same device. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5099], device='cuda:0')\n",
      "tensor([1.5099], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Recommended way for comapatibillity\n",
    "\n",
    "On systems with multiple GPU's there will be {`cuda:1`, `cuda:2`...} and so on.\n",
    "\n",
    "There is no automatic way to decide which GPU is \"free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "tensor = torch.zeros(2,2).to(device)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'RuntimeError'> expected device cpu but got device cuda:0\n"
     ]
    }
   ],
   "source": [
    "cpu = torch.ones(1)\n",
    "try:\n",
    "    cpu + tensor\n",
    "except Exception as e:\n",
    "    print(type(e), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Autograd: Automatic Differentiation\n",
    "===================================\n",
    "\n",
    "The ``autograd`` package provides automatic differentiation for all operations\n",
    "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
    "defined by how your code is run, and that every single iteration can be\n",
    "different.\n",
    "\n",
    "\n",
    "Tensor\n",
    "--------\n",
    "\n",
    "1. If you set its attribute``.requires_grad`` as ``True``, it starts to track all operations on it. \n",
    "\n",
    "2. When\n",
    "you finish your computation you can call ``.backward()`` and have all the\n",
    "gradients computed automatically. The gradient for this tensor will be\n",
    "accumulated into ``.grad`` attribute.\n",
    "\n",
    "3. To stop a tensor from tracking history, you can call ``.detach()`` to detach\n",
    "it from the computation history, and to prevent future computation from being\n",
    "tracked.\n",
    "\n",
    "4. To prevent tracking history (and using memory), you can also wrap the code block\n",
    "in ``with torch.no_grad():``. This can be particularly helpful when **evaluating a\n",
    "model** because the model may have trainable parameters with\n",
    "``requires_grad=True``, but for which we don't need the gradients.\n",
    "\n",
    "There’s one more class which is very important for autograd\n",
    "implementation - a ``Function``.\n",
    "\n",
    "``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. Each tensor has\n",
    "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Tensor`` (except for Tensors created by the user - their\n",
    "``grad_fn is None``).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a tensor and set ``requires_grad=True`` to track computation with it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Do a tensor operation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f076a3ca550>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Do more operations on ``y``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27., 27.],\n",
      "        [27., 27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
    "flag in-place. The input flag defaults to ``False`` if not given.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Gradients\n",
    "---------\n",
    "Let's backprop now.\n",
    "Because ``out`` contains a single scalar, ``out.backward()`` is\n",
    "equivalent to ``out.backward(torch.tensor(1.))``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print gradients d(out)/dx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's take a look at an example of vector-Jacobian product:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[102., 102.],\n",
      "        [102., 102.]])\n",
      "tensor([[142., 142.],\n",
      "        [142., 142.]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = torch.ones(2,2, requires_grad=True)\n",
    "x_2 = (x_1 ** 2 * 3).sum()\n",
    "x_2.backward(torch.tensor(17.))\n",
    "print(x_1.grad)\n",
    "x_3 = (x_1 * 20).sum()\n",
    "x_3.backward(torch.tensor(2.))\n",
    "print(x_1.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can also stop autograd from tracking history on Tensors\n",
    "with ``.requires_grad=True`` either by wrapping the code block in\n",
    "``with torch.no_grad():``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "\tprint((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Or by using ``.detach()`` to get a new Tensor with the same\n",
    "content but that does not require gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "y = x.detach()\n",
    "print(y.requires_grad)\n",
    "print(x.eq(y).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "# Neural Networks\n",
    "\n",
    "\n",
    "Neural networks can be constructed using the ``torch.nn`` package.\n",
    "\n",
    "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
    "``autograd`` to define models and differentiate them.\n",
    "An ``nn.Module`` contains layers, and a method ``forward(input)``\\ that\n",
    "returns the ``output``.\n",
    "\n",
    "For example, look at this network that classifies digit images:\n",
    "\n",
    "\n",
    "It is a simple feed-forward network. It takes the input, feeds it\n",
    "through several layers one after the other, and then finally gives the\n",
    "output.\n",
    "\n",
    "A typical training procedure for a neural network is as follows:\n",
    "\n",
    "- Define the neural network that has some learnable parameters (or\n",
    "  weights)\n",
    "- Iterate over a dataset of inputs\n",
    "- Process input through the network\n",
    "- Compute the loss (how far is the output from being correct)\n",
    "- Propagate gradients back into the network’s parameters\n",
    "- Update the weights of the network, typically using a simple update rule:\n",
    "  ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "Define the network\n",
    "------------------\n",
    "\n",
    "Let’s define this network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=1024, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# torch modules\n",
    "import torch.nn as nn\n",
    "# torch functions\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operations: y = Wx + b\n",
    "        self.fc1 = nn.Linear(32 * 32, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x.shape => BATCH_SIZE x Height X Width \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_with_sequential(\n",
      "  (dense_layers): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net_with_sequential(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net_with_sequential, self).__init__()\n",
    "        # an affine operations: y = Wx + b\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 32, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dense_layers(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "net_ws = Net_with_sequential()\n",
    "print(net_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just have to define the ``forward`` function, and the ``backward``\n",
    "function (where gradients are computed) is automatically defined for you\n",
    "using ``autograd``.\n",
    "You can use any of the Tensor operations in the ``forward`` function.\n",
    "\n",
    "The learnable parameters of a model are returned by ``net.parameters()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([200, 1024])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # fc1 .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a random 32x32 input.\n",
    "Note: expected input size of this net (LeNet) is 32x32. To use this net on\n",
    "the MNIST dataset, please resize the images from the dataset to 32x32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0179, -0.4377, -0.1136, -0.0297, -0.1533, -0.0356, -0.7116,  0.2119,\n",
      "         -0.3975,  0.0084]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input) #alias for net.forward(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random\n",
    "gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n",
    "    package only supports inputs that are a mini-batch of samples, and not\n",
    "    a single sample.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Loss Function\n",
    "-------------\n",
    "A loss function takes the (output, target) pair of inputs, and computes a\n",
    "value that estimates how far away the output is from the target.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5266, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you follow ``loss`` in the backward direction, using its\n",
    "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
    "like this:\n",
    "\n",
    "\n",
    "\n",
    "    input -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
    "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
    "will have their ``.grad`` Tensor accumulated with the gradient.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Backprop\n",
    "--------\n",
    "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
    "You need to clear the existing gradients though, else gradients will be\n",
    "accumulated to existing gradients.\n",
    "\n",
    "\n",
    "Now we shall call ``loss.backward()``, and have a look at linear bias\n",
    "gradients before and after the backward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "fc1.bias.grad after backward\n",
      "tensor([-1.2300e-03,  0.0000e+00,  0.0000e+00, -7.4418e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.2568e-02, -1.1713e-02,  0.0000e+00,  1.0256e-02,\n",
      "         0.0000e+00, -1.6844e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.8620e-02, -2.3067e-02, -1.1852e-02,\n",
      "        -1.0870e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4737e-02,\n",
      "         5.0465e-03,  0.0000e+00, -1.8777e-02, -4.1090e-02,  2.5733e-02,\n",
      "         0.0000e+00,  2.7732e-02,  2.3069e-02,  0.0000e+00,  0.0000e+00,\n",
      "         2.6086e-02,  0.0000e+00, -2.9180e-03,  0.0000e+00, -3.0627e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7916e-02,\n",
      "        -7.1186e-03,  2.1116e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -8.1264e-03, -5.7715e-03, -6.8669e-03,  0.0000e+00,\n",
      "         1.7213e-02,  4.2741e-03, -1.1512e-02,  0.0000e+00,  7.4121e-03,\n",
      "        -9.9355e-03,  1.1135e-02, -6.7645e-03,  0.0000e+00,  4.0953e-03,\n",
      "        -5.4288e-03,  0.0000e+00,  0.0000e+00, -2.3319e-02,  0.0000e+00,\n",
      "        -1.6361e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.0739e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1921e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -1.4876e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -2.2714e-02,  1.3403e-02, -6.4333e-03, -9.2964e-03,\n",
      "        -1.8763e-02,  0.0000e+00, -6.0976e-03, -3.2935e-02,  2.5491e-02,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2550e-02,  1.2291e-02,\n",
      "         3.0010e-02,  0.0000e+00, -2.3958e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  2.0675e-02,  3.2610e-03,  2.3813e-03,  0.0000e+00,\n",
      "         2.7292e-03, -4.9065e-02,  1.2835e-02,  0.0000e+00,  0.0000e+00,\n",
      "        -2.9095e-02,  0.0000e+00,  1.7836e-02,  0.0000e+00, -3.2031e-02,\n",
      "        -1.9387e-02,  4.5178e-03, -1.7244e-02,  0.0000e+00, -2.7569e-03,\n",
      "        -6.1290e-03,  0.0000e+00,  8.5123e-03,  0.0000e+00, -3.4331e-02,\n",
      "         2.7291e-03,  1.1123e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -4.7326e-02, -1.4649e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "        -1.3740e-02, -1.2106e-02, -3.0742e-03,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.7995e-05,  1.3889e-02,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.2302e-02,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.6559e-04,  0.0000e+00,  2.9498e-02,\n",
      "        -1.1465e-02, -1.2775e-02,  0.0000e+00, -7.5166e-03,  0.0000e+00,\n",
      "         2.0087e-02,  6.5708e-03,  0.0000e+00, -8.3257e-03,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  5.7180e-03,  0.0000e+00, -8.1093e-03,\n",
      "         0.0000e+00, -1.4997e-02,  0.0000e+00,  1.6319e-02,  0.0000e+00,\n",
      "        -7.5058e-03,  3.7208e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.0076e-02,  0.0000e+00, -2.3030e-02,  0.0000e+00,  0.0000e+00,\n",
      "        -7.2146e-03,  0.0000e+00, -5.3706e-03, -7.0506e-03,  0.0000e+00,\n",
      "         0.0000e+00, -1.0899e-02, -1.3011e-02,  0.0000e+00,  0.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('fc1.bias.grad before backward')\n",
    "print(net.fc1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('fc1.bias.grad after backward')\n",
    "print(net.fc1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Update the weights\n",
    "------------------\n",
    "The simplest update rule used in practice is the Stochastic Gradient\n",
    "Descent (SGD):\n",
    "\n",
    " ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "We can implement this using simple Python code:\n",
    "\n",
    "```\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "```\n",
    "However, as you use neural networks, you want to use various different\n",
    "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
    "To enable this, we built a small package: ``torch.optim`` that\n",
    "implements all these methods. Using it is very simple:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preparing a dataset\n",
    "\n",
    "A lot of effort in solving any machine learning problem goes in to preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable.\n",
    "\n",
    "Dataset class\n",
    "-------------\n",
    "\n",
    "``torch.utils.data.Dataset`` is an abstract class representing a\n",
    "dataset.\n",
    "Your custom dataset should inherit ``Dataset`` and override the following\n",
    "methods:\n",
    "\n",
    "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
    "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
    "   be used to get $i$'th sample\n",
    "\n",
    "\n",
    "Sample of our dataset will be a dict\n",
    "``{'image': image, 'label': label}``.\n",
    "\n",
    "### my_SimpleDataset\n",
    "\n",
    "Dataset containes images build form zeroes and ones.\n",
    "Our machine_learning task is to figure out if we have **more ones than zeros** in the picture. (This task is trivial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_len: 8192\n",
      "{'image': tensor([[0., 0., 1., 1., 1., 0., 0., 0., 1., 1.],\n",
      "        [1., 0., 0., 1., 0., 1., 1., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 0., 0., 1.],\n",
      "        [1., 0., 1., 0., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 0., 0., 1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0., 1., 1., 0., 0., 1.],\n",
      "        [1., 1., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
      "        [1., 0., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
      "        [1., 0., 0., 0., 1., 1., 1., 1., 1., 1.]]), 'label': tensor(1.)}\n",
      "looping sucesfull\n"
     ]
    }
   ],
   "source": [
    "PICTURE_SIZE = 10\n",
    "\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, size):\n",
    "        self.data = torch.zeros(size, PICTURE_SIZE, PICTURE_SIZE)\n",
    "        self.data[torch.rand_like(self.data) > 0.5] = 1.\n",
    "        \n",
    "        self.labels = torch.zeros(size)\n",
    "        self.labels[self.data.mean(dim=[1,2]) > 0.5] = 1.\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # Accepts scalars, tuples and dictionaries\n",
    "        return {\n",
    "                'image': self.data[item],\n",
    "                'label': self.labels[item]\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "dataset = SimpleDataset(2**13)\n",
    "# __len__\n",
    "print('dataset_len:', len(dataset))\n",
    "\n",
    "# __getitem__\n",
    "print(dataset[15])\n",
    "\n",
    "for x in dataset:\n",
    "    pass\n",
    "print('looping sucesfull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "However, we are losing a lot of features by using a simple ``for`` loop to\n",
    "iterate over the data. In particular, we are missing out on:\n",
    "\n",
    "-  Batching the data\n",
    "-  Shuffling the data\n",
    "-  Load the data in parallel using ``multiprocessing`` workers.\n",
    "\n",
    "``torch.utils.data.DataLoader`` is an iterator which provides all these\n",
    "features. Parameters used below should be clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=2\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NeuralNet definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 800\n",
    "\n",
    "class CustomDenseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNetwork, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "                nn.Linear(PICTURE_SIZE * PICTURE_SIZE, HIDDEN_SIZE),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(HIDDEN_SIZE, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, PICTURE_SIZE * PICTURE_SIZE)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "# Move model weigths to device\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = CustomDenseNetwork().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    loss_avg = 0.\n",
    "    acc_avg = 0.\n",
    "    for i, batch_data in (enumerate(dataloader)):\n",
    "        # Start with zeroing .grad fields in model\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # Move data to device\n",
    "        images = batch_data['image'].to(device)\n",
    "        labels = batch_data['label'].to(device)\n",
    "        \n",
    "        #Run neural net\n",
    "        out = net(images)\n",
    "\n",
    "        #Compute loss and apply autograd for model parameters\n",
    "        loss = ((out.view(-1) - labels)** 2).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update network weigths\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics generation\n",
    "        res = torch.where(\n",
    "                out.view(-1) > 0.5,\n",
    "                torch.tensor(1., device=device),\n",
    "                torch.tensor(0., device=device)\n",
    "        )\n",
    "        acc = (res == labels).sum()\n",
    "        loss_avg += loss\n",
    "        acc_avg += acc\n",
    "        if i % 30 == 0 and i != 0:\n",
    "            print(f'epoch:{e + 1:2d} step: {(i):3d} loss: {loss_avg / 30:.3f} acc: {acc_avg / (BATCH_SIZE * 30):.3f}')\n",
    "            acc_avg = 0.\n",
    "            loss_avg = 0.\n",
    "        # End of statistics generation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ProTip: mnist InMemDataLoder\n",
    "\n",
    "**Fast DataLoader** for **small datasets** (MNIST for example). On Colab, this code snippet sagnificantlly improves data loading time, which can have huge impact on duration of the traning. \n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    __initialized = False\n",
    "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
    "                 batch_sampler=None, drop_last=False):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        \n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError('batch_sampler option is mutually exclusive '\n",
    "                                 'with batch_size, shuffle, sampler, and '\n",
    "                                 'drop_last')\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler option is mutually exclusive with '\n",
    "                             'shuffle')\n",
    "            \n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "    \n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
    "            raise ValueError('{} attribute should not be set after {} is '\n",
    "                             'initialized'.format(attr, self.__class__.__name__))\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##### HOW TO USE! ###\n",
    "# Download raw data\n",
    "# !command runs shell command in jupyter notebook\n",
    "!pip install -q gdown httpimport\n",
    "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz\n",
    "\n",
    "#Extracting data\n",
    "with np.load('mnist.npz') as data:\n",
    "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
    "\n",
    "\n",
    "#Fast loader initialziation\n",
    "train_loader = InMemDataLoader(\n",
    "    (mnist_full_train_data, ), batch_size=25, shuffle=True)\n",
    "next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Used materials:\n",
    "* Deep Learning with PyTorch: A 60 Minute Blitz https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* Writing Custom Datasets, DataLoaders and Transforms https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralNet definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 800\n",
    "\n",
    "class CustomDenseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomDenseNetwork, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "                nn.Linear(PICTURE_SIZE * PICTURE_SIZE, HIDDEN_SIZE),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(HIDDEN_SIZE, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, PICTURE_SIZE * PICTURE_SIZE)\n",
    "        x = self.hidden(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step:  30 loss: 0.242 acc: 0.649\n",
      "epoch: 1 step:  60 loss: 0.226 acc: 0.656\n",
      "epoch: 1 step:  90 loss: 0.216 acc: 0.686\n",
      "epoch: 1 step: 120 loss: 0.212 acc: 0.681\n",
      "epoch: 1 step: 150 loss: 0.209 acc: 0.691\n",
      "epoch: 1 step: 180 loss: 0.202 acc: 0.730\n",
      "epoch: 1 step: 210 loss: 0.205 acc: 0.718\n",
      "epoch: 1 step: 240 loss: 0.196 acc: 0.753\n",
      "epoch: 2 step:  30 loss: 0.194 acc: 0.807\n",
      "epoch: 2 step:  60 loss: 0.184 acc: 0.782\n",
      "epoch: 2 step:  90 loss: 0.175 acc: 0.807\n",
      "epoch: 2 step: 120 loss: 0.180 acc: 0.810\n",
      "epoch: 2 step: 150 loss: 0.179 acc: 0.796\n",
      "epoch: 2 step: 180 loss: 0.179 acc: 0.796\n",
      "epoch: 2 step: 210 loss: 0.174 acc: 0.819\n",
      "epoch: 2 step: 240 loss: 0.169 acc: 0.822\n",
      "epoch: 3 step:  30 loss: 0.171 acc: 0.859\n",
      "epoch: 3 step:  60 loss: 0.163 acc: 0.822\n",
      "epoch: 3 step:  90 loss: 0.158 acc: 0.839\n",
      "epoch: 3 step: 120 loss: 0.163 acc: 0.816\n",
      "epoch: 3 step: 150 loss: 0.155 acc: 0.855\n",
      "epoch: 3 step: 180 loss: 0.159 acc: 0.825\n",
      "epoch: 3 step: 210 loss: 0.150 acc: 0.879\n",
      "epoch: 3 step: 240 loss: 0.150 acc: 0.870\n",
      "epoch: 4 step:  30 loss: 0.148 acc: 0.909\n",
      "epoch: 4 step:  60 loss: 0.147 acc: 0.858\n",
      "epoch: 4 step:  90 loss: 0.145 acc: 0.854\n",
      "epoch: 4 step: 120 loss: 0.141 acc: 0.861\n",
      "epoch: 4 step: 150 loss: 0.139 acc: 0.880\n",
      "epoch: 4 step: 180 loss: 0.143 acc: 0.871\n",
      "epoch: 4 step: 210 loss: 0.138 acc: 0.875\n",
      "epoch: 4 step: 240 loss: 0.137 acc: 0.882\n",
      "epoch: 5 step:  30 loss: 0.144 acc: 0.905\n",
      "epoch: 5 step:  60 loss: 0.133 acc: 0.890\n",
      "epoch: 5 step:  90 loss: 0.125 acc: 0.896\n",
      "epoch: 5 step: 120 loss: 0.129 acc: 0.888\n",
      "epoch: 5 step: 150 loss: 0.129 acc: 0.892\n",
      "epoch: 5 step: 180 loss: 0.126 acc: 0.878\n",
      "epoch: 5 step: 210 loss: 0.124 acc: 0.892\n",
      "epoch: 5 step: 240 loss: 0.123 acc: 0.894\n",
      "epoch: 6 step:  30 loss: 0.130 acc: 0.917\n",
      "epoch: 6 step:  60 loss: 0.118 acc: 0.913\n",
      "epoch: 6 step:  90 loss: 0.123 acc: 0.889\n",
      "epoch: 6 step: 120 loss: 0.118 acc: 0.901\n",
      "epoch: 6 step: 150 loss: 0.119 acc: 0.900\n",
      "epoch: 6 step: 180 loss: 0.121 acc: 0.898\n",
      "epoch: 6 step: 210 loss: 0.116 acc: 0.903\n",
      "epoch: 6 step: 240 loss: 0.114 acc: 0.909\n",
      "epoch: 7 step:  30 loss: 0.116 acc: 0.950\n",
      "epoch: 7 step:  60 loss: 0.114 acc: 0.890\n",
      "epoch: 7 step:  90 loss: 0.113 acc: 0.899\n",
      "epoch: 7 step: 120 loss: 0.111 acc: 0.919\n",
      "epoch: 7 step: 150 loss: 0.110 acc: 0.903\n",
      "epoch: 7 step: 180 loss: 0.114 acc: 0.914\n",
      "epoch: 7 step: 210 loss: 0.115 acc: 0.903\n",
      "epoch: 7 step: 240 loss: 0.110 acc: 0.916\n",
      "epoch: 8 step:  30 loss: 0.107 acc: 0.965\n",
      "epoch: 8 step:  60 loss: 0.107 acc: 0.902\n",
      "epoch: 8 step:  90 loss: 0.105 acc: 0.920\n",
      "epoch: 8 step: 120 loss: 0.104 acc: 0.917\n",
      "epoch: 8 step: 150 loss: 0.106 acc: 0.910\n",
      "epoch: 8 step: 180 loss: 0.111 acc: 0.896\n",
      "epoch: 8 step: 210 loss: 0.111 acc: 0.917\n",
      "epoch: 8 step: 240 loss: 0.107 acc: 0.916\n",
      "epoch: 9 step:  30 loss: 0.109 acc: 0.943\n",
      "epoch: 9 step:  60 loss: 0.102 acc: 0.923\n",
      "epoch: 9 step:  90 loss: 0.104 acc: 0.919\n",
      "epoch: 9 step: 120 loss: 0.102 acc: 0.935\n",
      "epoch: 9 step: 150 loss: 0.102 acc: 0.925\n",
      "epoch: 9 step: 180 loss: 0.100 acc: 0.918\n",
      "epoch: 9 step: 210 loss: 0.105 acc: 0.914\n",
      "epoch: 9 step: 240 loss: 0.100 acc: 0.927\n",
      "epoch:10 step:  30 loss: 0.107 acc: 0.948\n",
      "epoch:10 step:  60 loss: 0.101 acc: 0.920\n",
      "epoch:10 step:  90 loss: 0.096 acc: 0.921\n",
      "epoch:10 step: 120 loss: 0.099 acc: 0.923\n",
      "epoch:10 step: 150 loss: 0.100 acc: 0.925\n",
      "epoch:10 step: 180 loss: 0.096 acc: 0.929\n",
      "epoch:10 step: 210 loss: 0.104 acc: 0.923\n",
      "epoch:10 step: 240 loss: 0.097 acc: 0.931\n",
      "epoch:11 step:  30 loss: 0.099 acc: 0.967\n",
      "epoch:11 step:  60 loss: 0.103 acc: 0.892\n",
      "epoch:11 step:  90 loss: 0.098 acc: 0.924\n",
      "epoch:11 step: 120 loss: 0.096 acc: 0.932\n",
      "epoch:11 step: 150 loss: 0.093 acc: 0.932\n",
      "epoch:11 step: 180 loss: 0.097 acc: 0.928\n",
      "epoch:11 step: 210 loss: 0.096 acc: 0.922\n",
      "epoch:11 step: 240 loss: 0.097 acc: 0.925\n",
      "epoch:12 step:  30 loss: 0.102 acc: 0.955\n",
      "epoch:12 step:  60 loss: 0.090 acc: 0.936\n",
      "epoch:12 step:  90 loss: 0.098 acc: 0.918\n",
      "epoch:12 step: 120 loss: 0.092 acc: 0.932\n",
      "epoch:12 step: 150 loss: 0.097 acc: 0.924\n",
      "epoch:12 step: 180 loss: 0.095 acc: 0.932\n",
      "epoch:12 step: 210 loss: 0.095 acc: 0.928\n",
      "epoch:12 step: 240 loss: 0.092 acc: 0.944\n",
      "epoch:13 step:  30 loss: 0.099 acc: 0.972\n",
      "epoch:13 step:  60 loss: 0.091 acc: 0.941\n",
      "epoch:13 step:  90 loss: 0.094 acc: 0.925\n",
      "epoch:13 step: 120 loss: 0.094 acc: 0.930\n",
      "epoch:13 step: 150 loss: 0.095 acc: 0.933\n",
      "epoch:13 step: 180 loss: 0.096 acc: 0.924\n",
      "epoch:13 step: 210 loss: 0.095 acc: 0.922\n",
      "epoch:13 step: 240 loss: 0.093 acc: 0.935\n",
      "epoch:14 step:  30 loss: 0.097 acc: 0.966\n",
      "epoch:14 step:  60 loss: 0.093 acc: 0.932\n",
      "epoch:14 step:  90 loss: 0.094 acc: 0.938\n",
      "epoch:14 step: 120 loss: 0.096 acc: 0.926\n",
      "epoch:14 step: 150 loss: 0.086 acc: 0.935\n",
      "epoch:14 step: 180 loss: 0.090 acc: 0.947\n",
      "epoch:14 step: 210 loss: 0.092 acc: 0.933\n",
      "epoch:14 step: 240 loss: 0.098 acc: 0.927\n",
      "epoch:15 step:  30 loss: 0.090 acc: 0.976\n",
      "epoch:15 step:  60 loss: 0.091 acc: 0.934\n",
      "epoch:15 step:  90 loss: 0.092 acc: 0.929\n",
      "epoch:15 step: 120 loss: 0.091 acc: 0.940\n",
      "epoch:15 step: 150 loss: 0.095 acc: 0.934\n",
      "epoch:15 step: 180 loss: 0.097 acc: 0.921\n",
      "epoch:15 step: 210 loss: 0.094 acc: 0.940\n",
      "epoch:15 step: 240 loss: 0.092 acc: 0.947\n",
      "epoch:16 step:  30 loss: 0.096 acc: 0.967\n",
      "epoch:16 step:  60 loss: 0.094 acc: 0.938\n",
      "epoch:16 step:  90 loss: 0.087 acc: 0.951\n",
      "epoch:16 step: 120 loss: 0.089 acc: 0.942\n",
      "epoch:16 step: 150 loss: 0.093 acc: 0.933\n",
      "epoch:16 step: 180 loss: 0.090 acc: 0.946\n",
      "epoch:16 step: 210 loss: 0.091 acc: 0.939\n",
      "epoch:16 step: 240 loss: 0.091 acc: 0.939\n",
      "epoch:17 step:  30 loss: 0.091 acc: 0.971\n",
      "epoch:17 step:  60 loss: 0.091 acc: 0.949\n",
      "epoch:17 step:  90 loss: 0.092 acc: 0.943\n",
      "epoch:17 step: 120 loss: 0.095 acc: 0.926\n",
      "epoch:17 step: 150 loss: 0.087 acc: 0.934\n",
      "epoch:17 step: 180 loss: 0.093 acc: 0.939\n",
      "epoch:17 step: 210 loss: 0.092 acc: 0.933\n",
      "epoch:17 step: 240 loss: 0.089 acc: 0.936\n",
      "epoch:18 step:  30 loss: 0.096 acc: 0.957\n",
      "epoch:18 step:  60 loss: 0.085 acc: 0.947\n",
      "epoch:18 step:  90 loss: 0.092 acc: 0.948\n",
      "epoch:18 step: 120 loss: 0.087 acc: 0.948\n",
      "epoch:18 step: 150 loss: 0.088 acc: 0.938\n",
      "epoch:18 step: 180 loss: 0.090 acc: 0.944\n",
      "epoch:18 step: 210 loss: 0.090 acc: 0.944\n",
      "epoch:18 step: 240 loss: 0.087 acc: 0.948\n",
      "epoch:19 step:  30 loss: 0.091 acc: 0.981\n",
      "epoch:19 step:  60 loss: 0.087 acc: 0.951\n",
      "epoch:19 step:  90 loss: 0.088 acc: 0.932\n",
      "epoch:19 step: 120 loss: 0.092 acc: 0.934\n",
      "epoch:19 step: 150 loss: 0.091 acc: 0.943\n",
      "epoch:19 step: 180 loss: 0.084 acc: 0.961\n",
      "epoch:19 step: 210 loss: 0.089 acc: 0.934\n",
      "epoch:19 step: 240 loss: 0.091 acc: 0.949\n",
      "epoch:20 step:  30 loss: 0.087 acc: 0.978\n",
      "epoch:20 step:  60 loss: 0.088 acc: 0.935\n",
      "epoch:20 step:  90 loss: 0.089 acc: 0.943\n",
      "epoch:20 step: 120 loss: 0.089 acc: 0.944\n",
      "epoch:20 step: 150 loss: 0.088 acc: 0.943\n",
      "epoch:20 step: 180 loss: 0.091 acc: 0.944\n",
      "epoch:20 step: 210 loss: 0.092 acc: 0.938\n",
      "epoch:20 step: 240 loss: 0.089 acc: 0.947\n",
      "epoch:21 step:  30 loss: 0.086 acc: 0.991\n",
      "epoch:21 step:  60 loss: 0.089 acc: 0.951\n",
      "epoch:21 step:  90 loss: 0.087 acc: 0.944\n",
      "epoch:21 step: 120 loss: 0.087 acc: 0.940\n",
      "epoch:21 step: 150 loss: 0.088 acc: 0.944\n",
      "epoch:21 step: 180 loss: 0.091 acc: 0.949\n",
      "epoch:21 step: 210 loss: 0.087 acc: 0.949\n",
      "epoch:21 step: 240 loss: 0.089 acc: 0.942\n",
      "epoch:22 step:  30 loss: 0.090 acc: 0.986\n",
      "epoch:22 step:  60 loss: 0.086 acc: 0.944\n",
      "epoch:22 step:  90 loss: 0.086 acc: 0.951\n",
      "epoch:22 step: 120 loss: 0.090 acc: 0.954\n",
      "epoch:22 step: 150 loss: 0.088 acc: 0.950\n",
      "epoch:22 step: 180 loss: 0.090 acc: 0.929\n",
      "epoch:22 step: 210 loss: 0.086 acc: 0.947\n",
      "epoch:22 step: 240 loss: 0.090 acc: 0.944\n",
      "epoch:23 step:  30 loss: 0.091 acc: 0.979\n",
      "epoch:23 step:  60 loss: 0.089 acc: 0.952\n",
      "epoch:23 step:  90 loss: 0.086 acc: 0.947\n",
      "epoch:23 step: 120 loss: 0.086 acc: 0.944\n",
      "epoch:23 step: 150 loss: 0.088 acc: 0.950\n",
      "epoch:23 step: 180 loss: 0.085 acc: 0.945\n",
      "epoch:23 step: 210 loss: 0.086 acc: 0.950\n",
      "epoch:23 step: 240 loss: 0.085 acc: 0.946\n",
      "epoch:24 step:  30 loss: 0.086 acc: 0.988\n",
      "epoch:24 step:  60 loss: 0.087 acc: 0.951\n",
      "epoch:24 step:  90 loss: 0.088 acc: 0.936\n",
      "epoch:24 step: 120 loss: 0.086 acc: 0.950\n",
      "epoch:24 step: 150 loss: 0.085 acc: 0.965\n",
      "epoch:24 step: 180 loss: 0.088 acc: 0.947\n",
      "epoch:24 step: 210 loss: 0.085 acc: 0.958\n",
      "epoch:24 step: 240 loss: 0.085 acc: 0.952\n",
      "epoch:25 step:  30 loss: 0.086 acc: 0.993\n",
      "epoch:25 step:  60 loss: 0.083 acc: 0.942\n",
      "epoch:25 step:  90 loss: 0.086 acc: 0.946\n",
      "epoch:25 step: 120 loss: 0.085 acc: 0.948\n",
      "epoch:25 step: 150 loss: 0.086 acc: 0.950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step: 180 loss: 0.083 acc: 0.965\n",
      "epoch:25 step: 210 loss: 0.088 acc: 0.951\n",
      "epoch:25 step: 240 loss: 0.088 acc: 0.943\n",
      "epoch:26 step:  30 loss: 0.085 acc: 0.983\n",
      "epoch:26 step:  60 loss: 0.085 acc: 0.955\n",
      "epoch:26 step:  90 loss: 0.087 acc: 0.951\n",
      "epoch:26 step: 120 loss: 0.083 acc: 0.953\n",
      "epoch:26 step: 150 loss: 0.088 acc: 0.947\n",
      "epoch:26 step: 180 loss: 0.081 acc: 0.958\n",
      "epoch:26 step: 210 loss: 0.087 acc: 0.949\n",
      "epoch:26 step: 240 loss: 0.088 acc: 0.953\n",
      "epoch:27 step:  30 loss: 0.088 acc: 0.983\n",
      "epoch:27 step:  60 loss: 0.085 acc: 0.955\n",
      "epoch:27 step:  90 loss: 0.082 acc: 0.951\n",
      "epoch:27 step: 120 loss: 0.087 acc: 0.955\n",
      "epoch:27 step: 150 loss: 0.085 acc: 0.954\n",
      "epoch:27 step: 180 loss: 0.085 acc: 0.949\n",
      "epoch:27 step: 210 loss: 0.084 acc: 0.954\n",
      "epoch:27 step: 240 loss: 0.081 acc: 0.951\n",
      "epoch:28 step:  30 loss: 0.083 acc: 0.995\n",
      "epoch:28 step:  60 loss: 0.087 acc: 0.956\n",
      "epoch:28 step:  90 loss: 0.087 acc: 0.950\n",
      "epoch:28 step: 120 loss: 0.084 acc: 0.956\n",
      "epoch:28 step: 150 loss: 0.087 acc: 0.954\n",
      "epoch:28 step: 180 loss: 0.085 acc: 0.966\n",
      "epoch:28 step: 210 loss: 0.079 acc: 0.963\n",
      "epoch:28 step: 240 loss: 0.084 acc: 0.951\n",
      "epoch:29 step:  30 loss: 0.086 acc: 0.995\n",
      "epoch:29 step:  60 loss: 0.084 acc: 0.955\n",
      "epoch:29 step:  90 loss: 0.090 acc: 0.951\n",
      "epoch:29 step: 120 loss: 0.082 acc: 0.950\n",
      "epoch:29 step: 150 loss: 0.080 acc: 0.960\n",
      "epoch:29 step: 180 loss: 0.082 acc: 0.957\n",
      "epoch:29 step: 210 loss: 0.083 acc: 0.959\n",
      "epoch:29 step: 240 loss: 0.084 acc: 0.955\n",
      "epoch:30 step:  30 loss: 0.081 acc: 0.998\n",
      "epoch:30 step:  60 loss: 0.079 acc: 0.959\n",
      "epoch:30 step:  90 loss: 0.083 acc: 0.949\n",
      "epoch:30 step: 120 loss: 0.083 acc: 0.960\n",
      "epoch:30 step: 150 loss: 0.083 acc: 0.953\n",
      "epoch:30 step: 180 loss: 0.090 acc: 0.940\n",
      "epoch:30 step: 210 loss: 0.084 acc: 0.961\n",
      "epoch:30 step: 240 loss: 0.081 acc: 0.952\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "# Move model weigths to device\n",
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "net = CustomDenseNetwork().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "\n",
    "for e in range(EPOCHS):\n",
    "    loss_avg = 0.\n",
    "    acc_avg = 0.\n",
    "    for i, batch_data in (enumerate(dataloader)):\n",
    "        # Start with zeroing .grad fields in model\n",
    "        net.zero_grad()\n",
    "        \n",
    "        # Move data to device\n",
    "        images = batch_data['image'].to(device)\n",
    "        labels = batch_data['label'].to(device)\n",
    "        \n",
    "        #Run neural net\n",
    "        out = net(images)\n",
    "\n",
    "        #Compute loss and apply autograd for model parameters\n",
    "        loss = ((out.view(-1) - labels)** 2).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update network weigths\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics generation\n",
    "        res = torch.where(\n",
    "                out.view(-1) > 0.5,\n",
    "                torch.tensor(1., device=device),\n",
    "                torch.tensor(0., device=device)\n",
    "        )\n",
    "        acc = (res == labels).sum()\n",
    "        loss_avg += loss\n",
    "        acc_avg += acc\n",
    "        if i % 30 == 0 and i != 0:\n",
    "            print(f'epoch:{e + 1:2d} step: {(i):3d} loss: {loss_avg / 30:.3f} acc: {acc_avg / (BATCH_SIZE * 30):.3f}')\n",
    "            acc_avg = 0.\n",
    "            loss_avg = 0.\n",
    "        # End of statistics generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProTip: mnist InMemDataLoder\n",
    "\n",
    "**Fast DataLoader** for **small datasets** (MNIST for example). On Colab, this code snippet sagnificantlly improves data loading time, which can have huge impact on duration of the traning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    __initialized = False\n",
    "    def __init__(self, tensors, batch_size=1, shuffle=False, sampler=None,\n",
    "                 batch_sampler=None, drop_last=False):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        tensors = [torch.tensor(tensor) for tensor in tensors]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "        \n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError('batch_sampler option is mutually exclusive '\n",
    "                                 'with batch_size, shuffle, sampler, and '\n",
    "                                 'drop_last')\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler option is mutually exclusive with '\n",
    "                             'shuffle')\n",
    "            \n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "    \n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
    "            raise ValueError('{} attribute should not be set after {} is '\n",
    "                             'initialized'.format(attr, self.__class__.__name__))\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### HOW TO USE! ###\n",
    "# Download raw data\n",
    "# !command runs shell command in jupyter notebook\n",
    "!pip install -q gdown httpimport\n",
    "![ -e mnist.npz ] || gdown 'https://drive.google.com/uc?id=1QPaC3IKB_5tX6yIZgRgkpcqFrfVqPTXU' -O mnist.npz\n",
    "\n",
    "#Extracting data\n",
    "with np.load('mnist.npz') as data:\n",
    "    mnist_full_train_data = data['train_data'].astype('float32') / 255.0\n",
    "\n",
    "\n",
    "#Fast loader initialziation\n",
    "train_loader = InMemDataLoader(\n",
    "    (mnist_full_train_data, ), batch_size=25, shuffle=True)\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "source": [
    "Used materials:\n",
    "* Deep Learning with PyTorch: A 60 Minute Blitz https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "* Writing Custom Datasets, DataLoaders and Transforms https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}